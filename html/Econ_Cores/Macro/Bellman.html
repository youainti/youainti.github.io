<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>EconStuff</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <script src="/node_modules/mathjax/es5/tex-chtml.js" type="text/javascript"></script>
</head>
<body>
<h1 id="deriving-the-bellman-equation">Deriving the Bellman Equation</h1>
<h2 id="problem-statement">Problem Statement</h2>
<p>A common problem statment follow the pattern <span class="math display">\[\begin{align}
    \max_{(x_t,c_t)^\infty_{t=0}} &amp; \sum_{t=0}^\infty \big[ \beta^t u(c_t) \big] \\
    &amp; \text{Subject To: } x_{t+1} + c_t = f(x_t)
\end{align}\]</span></p>
<p>We need to transform this into the recursive bellman form.</p>
<h2 id="important-math">Important Math</h2>
<h4 id="principle-of-optimality">Principle of Optimality:</h4>
<p>An optimal policy has the property that whatever the initial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision. <a href="https://en.wikipedia.org/wiki/Bellman_equation#Bellman&#39;s_principle_of_optimality">Wikipedia: The Bellman Equation</a></p>
<p>Thus the following has the optimal property. <span class="math display">\[
\max_{(a_i)^n_{i=1}} \sum_{i=1}^n f(a_i) = \max_{a_1} f(a_1) 
    + \max_{(a_i)^n_{i=2}} \sum_{i=2}^n f(a_i)
\]</span></p>
<h4 id="envelope-theorem">Envelope Theorem</h4>
<p>The envelope theorem simplifies the chain rule under the case of optimal solutions.</p>
<p>Given the following policy function: <span class="math display">\[
y(x) = \text{argmax}_{y} f(x,y)
\]</span> In the context of <span class="math display">\[
V(x) = \max_{y} f(x,y)
\]</span> Then if <span class="math inline">\(y(x)\)</span> is a functional solution to the above, the envelope theorem states: <span class="math display">\[
\frac{\partial}{\partial x} V(x) =
    \frac{\partial}{\partial x} f(x,y(x)) 
\]</span></p>
<h2 id="bellmanizing">Bellmanizing!</h2>
<p><span class="math display">\[\begin{align}
    V(x_0) &amp;= \max_{(x_t,c_t)^\infty_{t=0}} \sum_{t=0}^\infty \big[ \beta^t f(x) \big] \\
    &amp; = \max_{x_1} f(x_0) +\beta \max_{(x_t)^\infty_{t=1}}  \sum_{t=0}^\infty \big[ \beta^t f(x_t) \big] \\
    &amp; = \max_{x_0} f(x_0) + \beta V(x_1(x_0))
\end{align}\]</span></p>
<h2 id="solution-concepts">Solution Concepts</h2>
<p>We can “solve” the bellman equation by taking FOCs with respect to the choice variables (Choice variables were not included explicitly in my description).</p>
<h3 id="policy-functions">Policy Functions</h3>
<p>One solution concept is collecting only the policy or choice functions that describe the optimal choices of the agents involved.</p>
<h4 id="euler-equations">Euler Equations</h4>
<p>Here are some useful definitions.</p>
<table>
<colgroup>
<col style="width: 12%" />
<col style="width: 12%" />
<col style="width: 25%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Item</th>
<th style="text-align: left;">Type</th>
<th style="text-align: left;">Mathematical Description</th>
<th style="text-align: left;">English Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_t\)</span></td>
<td style="text-align: left;">Variable</td>
<td style="text-align: left;"><span class="math inline">\(x_t \in X \subset R^k\)</span></td>
<td style="text-align: left;">The state variables.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(y_t\)</span></td>
<td style="text-align: left;">Variable</td>
<td style="text-align: left;"><span class="math inline">\(y_t \in Y \subset R^j\)</span></td>
<td style="text-align: left;">The control variables.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(V\)</span></td>
<td style="text-align: left;">Function</td>
<td style="text-align: left;"><span class="math inline">\(V: X \rightarrow R\)</span></td>
<td style="text-align: left;">The value function.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(F\)</span></td>
<td style="text-align: left;">Function</td>
<td style="text-align: left;"><span class="math inline">\(F: X\times Y \rightarrow R\)</span></td>
<td style="text-align: left;">The time seperable objective function.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(g\)</span></td>
<td style="text-align: left;">Function</td>
<td style="text-align: left;"><span class="math inline">\(g: X\times Y \rightarrow X\)</span></td>
<td style="text-align: left;">The equality constraints mapping state and controls to next period state.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(h_u\)</span></td>
<td style="text-align: left;">Function</td>
<td style="text-align: left;"><span class="math inline">\(h_u: X\times Y \rightarrow [0]^m\)</span></td>
<td style="text-align: left;">The upper inequality constraints on variables.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(h_l\)</span></td>
<td style="text-align: left;">Function</td>
<td style="text-align: left;"><span class="math inline">\(h_l: X\times Y \rightarrow [0]^n\)</span></td>
<td style="text-align: left;">The lower inequality constraints on variables.</td>
</tr>
</tbody>
</table>
<p>This can probably be written with inequality constraints on both state and control variables.</p>
<p>The bellman will take the form: <span class="math display">\[\begin{align}
    V(x_t) &amp;= \max_{y_t} F(x_t, y_t) + \beta V(x_{t+1}) \\
    \text{subject to:} \\
    &amp; x_{t+1} = g(x_t,y_t) \\
    &amp; 0 \geq h_u(x_t, y_t) \\
    &amp; 0 \leq h_l(x_t, y_t) \\
\end{align}\]</span> With the inequality constraints, we use KKT to find: <span class="math display">\[\begin{align}
    L &amp;= \max_{y_t} F(xt_t,y_t) + \beta V(x_{t+1}) 
        - \mu \left[ x_{t+1} - g(x_t, y_t) \right]
        + \lambda  h_l(x_t) 
        - \omega  h_u(x_t)  \\
    L &amp;= \max_{y_t} F(xt_t,y_t) + \beta V\left[ g(x_t,y_t) \right]
        + \lambda  h_l(x_t) 
        - \omega  h_u(x_t)  \\
\end{align}\]</span> This gives us the <span class="math inline">\(j\)</span> FOCs and <span class="math inline">\(m+n\)</span> KKT Conditions: <span class="math display">\[\begin{align}
    [0] = D_y L &amp;= D_y F(x_t, y_t) + \beta D^T_{x_{t+1}} V(g(x_t,y_t)) \cdot D_y g(x_t,y_t)
        + \lambda D_y h_l(x_t) 
        - \omega D_y h_u(x_t)  \\
    [0] &amp;= \lambda h_l(x_t) \\
    [0] &amp;= \omega  h_u(x_t)  \\
\end{align}\]</span></p>
<p>Now we must use the envelope theorem to handle the <span class="math inline">\(D^T V()\)</span> vector. Let <span class="math inline">\(y_t (x_t)\)</span> represent the optimal policy functions.</p>
<p><span class="math display">\[\begin{align}
D_{x_t} V(x_t) &amp;= D_{x_t} F(x_t, y_t(x_t)) \\
D^T_{x_{t+1}} V(x_{t+1}) &amp;= D^T_{x_{t+1}} F(x_{t+1}, y_{t+1}(x_{t+1})) 
\end{align}\]</span></p>
<p>Thus we get the set of Euler Equations and KKT Conditions: <span class="math display">\[\begin{align}
    [0]  &amp;= D_y F(x_t, y_t) 
        + \beta D^T_{x_{t+1}} F(x_{t+1}, y_{t+1}(x_{t+1})) \cdot D_y g(x_t,y_t)
        + \lambda D_y h_l(x_t) 
        - \omega D_y h_u(x_t)  \\
    [0] &amp;= \lambda h_l(x_t) \\
    [0] &amp;= \omega  h_u(x_t)  \\
\end{align}\]</span> Don’t forget to include probabilities and states in the case you are dealing with a stochastic version.</p>
<h5 id="guess-and-check">Guess and Check</h5>
<p>If you have a guess for the form of the optimal policy functions, you can now substitute and solve for them.</p>
<h5 id="policy-function-iteration">Policy Function Iteration</h5>
<p>This gives you a way to get a numerical (or symbolic if you can do the functional limits) representation of the policy functions.</p>
<h3 id="value-functions">Value Functions</h3>
<p>The Value Function solution concept builds on the idea of the policy function approach to calculate the overall utility value under the optimal policy.</p>
<h4 id="value-function-iteration">Value Function Iteration</h4>
<h4 id="guess-and-check-1">Guess and Check</h4>
</body>
</html>
